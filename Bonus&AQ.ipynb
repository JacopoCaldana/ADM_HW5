{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus Question - Connected Components on MapReduce"
      ],
      "metadata": {
        "id": "BmJl0PVFuc2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MapReduce is ideal for network analysis as it enables parallel processing of large graph datasets, making it scalable and efficient. By breaking tasks into map and reduce steps, it allows for distributed analysis of networks, which is essential for handling large-scale graph problems like connected components.\n",
        "\n",
        "### 1. In this task, you are required to use PySpark and the MapReduce paradigm to identify the connected components in a flight network graph. The focus should be on airports rather than cities. As you know, a connected component refers to a group of airports where every pair of airports within the group is connected either directly or indirectly.\n",
        "\n",
        "### The function takes the following inputs:\n",
        "\n",
        "### 1. Flight network\n",
        "### 2. A starting date\n",
        "### 3. An end date\n",
        "\n",
        "### The function outputs:\n",
        "### 1. The number of the connected components during that period\n",
        "### 2. The size of each connectd componenet\n",
        "### 3. The airports within the largest connected component identified.\n",
        "\n",
        "### **Note**: For this task, you should check if there is a flight between two airports during that period. Note: You are not allowed to use pre-existing packages or functions in PySpark; instead, you must implement the algorithm from scratch using the MapReduce paradigm."
      ],
      "metadata": {
        "id": "qqvRXoRKuqUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mounting Google Drive and Installing Necessary Packages"
      ],
      "metadata": {
        "id": "IQnI1M7s0PNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4aaNqzOE4AW",
        "outputId": "22ab5144-57ff-4624-c3e3-c8f1099de0f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN_iwv1SlV2u",
        "outputId": "a8f68c70-ebb7-4a90-aabf-85059d7a2320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.2)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: yellowbrick in /usr/local/lib/python3.10/dist-packages (1.5)\n",
            "Requirement already satisfied: graphframes in /usr/local/lib/python3.10/dist-packages (0.6)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (1.26.4)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from yellowbrick) (0.12.1)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.10/dist-packages (from graphframes) (1.3.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.0.0,>=2.0.2->yellowbrick) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->yellowbrick) (3.5.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.2->yellowbrick) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Install PySpark and all the necessary packages\n",
        "! pip install pyngrok gdown  pyspark  yellowbrick graphframes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, StorageLevel\n",
        "from pyspark.sql.functions import col, explode, collect_list, min, to_date as spark_min, struct, size, row_number, to_date\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql import functions as F\n",
        "from graphframes import GraphFrame\n",
        "import time\n",
        "import json\n",
        "import tempfile\n",
        "import os"
      ],
      "metadata": {
        "id": "dXGrt77qV26w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2nhAXColV2u",
        "outputId": "0e9fd96d-24a5-42d1-8d25-18d5f371afff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Spark Session...\n",
            "... Spark Session Created\n"
          ]
        }
      ],
      "source": [
        "# Get the active SparkContext instance\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "# Stop SparkContext if you want to create a new one\n",
        "sc.stop()\n",
        "\n",
        "# Initialize Spark Session with configurations\n",
        "print(\"Initializing Spark Session...\")\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Connected Components Analysis\") \\\n",
        "    .config(\"spark.driver.memory\", \"15g\") \\\n",
        "    .config(\"spark.executor.memory\", \"15g\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.adaptive.skewJoin.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"100\") \\\n",
        "    .getOrCreate()\n",
        "print(\"... Spark Session Created\")\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading and Preparing the Flight Network Dataset\n",
        "\n",
        "We perform the following operations to load and prepare the flight network dataset for analysis:\n",
        "\n",
        "1. **Loading the Dataset with Pandas**;\n",
        "\n",
        "2. **Converting Pandas DataFrame to Spark DataFrame**;\n",
        "\n",
        "3. **Displaying the Schema of the Spark DataFrame**.\n",
        "\n"
      ],
      "metadata": {
        "id": "RoYkq-Op0rn8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iXmcjUIdlV2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55471319-5fdb-4fe0-94d6-9fe791417e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Origin_airport: string (nullable = true)\n",
            " |-- Destination_airport: string (nullable = true)\n",
            " |-- Origin_city: string (nullable = true)\n",
            " |-- Destination_city: string (nullable = true)\n",
            " |-- Passengers: long (nullable = true)\n",
            " |-- Seats: long (nullable = true)\n",
            " |-- Flights: long (nullable = true)\n",
            " |-- Distance: long (nullable = true)\n",
            " |-- Fly_date: string (nullable = true)\n",
            " |-- Origin_population: long (nullable = true)\n",
            " |-- Destination_population: long (nullable = true)\n",
            " |-- Org_airport_lat: double (nullable = true)\n",
            " |-- Org_airport_long: double (nullable = true)\n",
            " |-- Dest_airport_lat: double (nullable = true)\n",
            " |-- Dest_airport_long: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset as a DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/Airports2.csv')\n",
        "flight_network_df = spark.createDataFrame(df)\n",
        "\n",
        "# Display the schema to confirm\n",
        "flight_network_df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define two crucial functions, `propagate_labels` and `identify_connected_components_rdd`, which work together to identify connected components within a flight network dataset using Spark's Resilient Distributed Datasets (RDDs). This approach leverages low-level Spark transformations and actions for efficient graph processing.\n",
        "- The `propagate_labels` function is a helper function designed to facilitate the iterative process of label propagation, a key step in identifying connected components within a graph. By propagating the smallest label across connected nodes, the function ensures that all nodes within the same connected component eventually share the same label.\n",
        "- The `identify_connected_components_rdd` function is designed to identify connected components within a flight network dataset over a specified date range using Spark's RDD API. Connected components represent groups of airports where each airport is reachable from any other airport within the same group, indicating a fully interconnected sub-network.\n"
      ],
      "metadata": {
        "id": "rIForu8V170L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import builtins\n",
        "from pyspark.sql.functions import to_date, col\n",
        "from pyspark import StorageLevel\n",
        "import time\n",
        "\n",
        "def propagate_labels(labels_rdd, graph_rdd):\n",
        "    \"\"\"\n",
        "    Propagates labels through the graph to identify connected components.\n",
        "\n",
        "    Parameters:\n",
        "    - labels_rdd (RDD of tuples): Current labels as (airport_id, label_id).\n",
        "    - graph_rdd (RDD of tuples): Graph edges as (airport_id, list of neighbor_ids).\n",
        "\n",
        "    Returns:\n",
        "    - new_labels (RDD of tuples): Updated labels after propagation as (airport_id, new_label_id).\n",
        "    \"\"\"\n",
        "    # Join graph with current labels to get the label of each airport's neighbors\n",
        "    joined = graph_rdd.join(labels_rdd)\n",
        "\n",
        "    # Create messages to propagate the smallest label to each neighbor\n",
        "    messages = joined.flatMap(lambda x: [(neighbor, x[1][1]) for neighbor in x[1][0]])\n",
        "\n",
        "    # Combine incoming messages with existing labels and choose the minimum label\n",
        "    new_labels = messages.union(labels_rdd).reduceByKey(lambda a, b: builtins.min(a, b))\n",
        "\n",
        "    return new_labels\n",
        "\n",
        "def identify_connected_components_rdd(flight_network_df, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Identifies the connected components in the flight network between start_date and end_date.\n",
        "\n",
        "    Parameters:\n",
        "    - flight_network_df (DataFrame): Spark DataFrame containing flight data with columns\n",
        "                                      'Origin_airport', 'Destination_airport', 'Fly_date'.\n",
        "    - start_date (str): Start date of the period in 'YYYY-MM-DD' format.\n",
        "    - end_date (str): End date of the period in 'YYYY-MM-DD' format.\n",
        "\n",
        "    Returns:\n",
        "    - num_connected_components (int): Number of connected components.\n",
        "    - component_sizes_sorted (list of tuples): List of component sizes sorted in descending order.\n",
        "    - largest_component_airports (list): List of airports in the largest connected component.\n",
        "    - execution_time (float): Time taken to execute the function in seconds.\n",
        "    \"\"\"\n",
        "\n",
        "    # Filter flights within the specified date range and drop rows with null airports\n",
        "    filtered_df = flight_network_df.filter(\n",
        "        (col(\"Fly_date\") >= start_date) & (col(\"Fly_date\") <= end_date)\n",
        "    ).na.drop(subset=[\"Origin_airport\", \"Destination_airport\"])\n",
        "\n",
        "    # Create edges by selecting origin and destination airports and ensuring uniqueness\n",
        "    edges = filtered_df.select(\n",
        "        col(\"Origin_airport\").alias(\"src\"),\n",
        "        col(\"Destination_airport\").alias(\"dst\")\n",
        "    ).rdd.map(lambda row: (row[\"src\"], row[\"dst\"])).distinct()\n",
        "\n",
        "    # Create reverse edges to make the graph undirected\n",
        "    reverse_edges = edges.map(lambda edge: (edge[1], edge[0]))\n",
        "    all_edges = edges.union(reverse_edges).distinct()\n",
        "\n",
        "    # Extract all unique airports from the edges\n",
        "    airports = all_edges.flatMap(lambda edge: edge).distinct()\n",
        "\n",
        "    # Assign unique IDs to each airport\n",
        "    airport_id = airports.zipWithIndex().map(lambda x: (x[0], x[1]))\n",
        "    id_to_airport = airport_id.map(lambda x: (x[1], x[0])).collectAsMap()\n",
        "    airport_id_dict = airport_id.collectAsMap()\n",
        "\n",
        "    # Broadcast the ID mappings for efficient access across the cluster\n",
        "    broadcast_id_to_airport = flight_network_df.sparkSession.sparkContext.broadcast(id_to_airport)\n",
        "    broadcast_airport_id = flight_network_df.sparkSession.sparkContext.broadcast(airport_id_dict)\n",
        "\n",
        "    # Map edges using the integer IDs\n",
        "    all_edges_id = all_edges.map(lambda x: (broadcast_airport_id.value[x[0]], broadcast_airport_id.value[x[1]])).distinct()\n",
        "\n",
        "    # Build the graph as an RDD of (airport, list of neighbors)\n",
        "    graph = all_edges_id.groupByKey().mapValues(list).persist(StorageLevel.MEMORY_AND_DISK)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Initialize labels: each airport's label is its own ID initially\n",
        "    labels = all_edges_id.flatMap(lambda x: [x[0], x[1]]).distinct().map(lambda airport: (airport, airport)).persist(StorageLevel.MEMORY_AND_DISK)\n",
        "\n",
        "    # Iteratively propagate labels until convergence or maximum iterations are reached\n",
        "    current_labels = labels\n",
        "    prev_labels = None\n",
        "    iteration = 0\n",
        "    MAX_ITERATIONS = 100  # Limit to prevent infinite loops\n",
        "\n",
        "    while iteration < MAX_ITERATIONS:\n",
        "        iteration += 1\n",
        "        print(f\"Iteration {iteration}\")\n",
        "\n",
        "        # Propagate labels\n",
        "        new_labels = propagate_labels(current_labels, graph).persist(StorageLevel.MEMORY_AND_DISK)\n",
        "\n",
        "        # Check for convergence by comparing with previous labels\n",
        "        if prev_labels:\n",
        "            differences = current_labels.join(new_labels) \\\n",
        "                .filter(lambda x: x[1][0] != x[1][1]) \\\n",
        "                .count()\n",
        "            print(f\"Differences from the previous iteration: {differences}\")\n",
        "            if differences == 0:\n",
        "                print(\"Convergence achieved.\")\n",
        "                break\n",
        "        else:\n",
        "            print(\"First iteration, no comparison.\")\n",
        "\n",
        "        # Unpersist previous labels to free up memory\n",
        "        if prev_labels:\n",
        "            prev_labels.unpersist()\n",
        "\n",
        "        # Update labels for the next iteration\n",
        "        prev_labels = current_labels\n",
        "        current_labels = new_labels\n",
        "\n",
        "    # Warn if maximum iterations were reached without convergence\n",
        "    if iteration == MAX_ITERATIONS:\n",
        "        print(\"Warning: Maximum number of iterations reached without convergence.\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "\n",
        "    # Collect the final labels\n",
        "    final_labels = current_labels\n",
        "\n",
        "    # Count the number of distinct connected components\n",
        "    num_connected_components = final_labels.map(lambda x: x[1]).distinct().count()\n",
        "\n",
        "    # Count the number of airports in each connected component\n",
        "    component_sizes = final_labels.map(lambda x: (x[1], 1)).reduceByKey(lambda a, b: a + b).collect()\n",
        "\n",
        "    # Sort the component sizes in descending order\n",
        "    component_sizes_sorted = sorted(component_sizes, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Identify the largest connected component\n",
        "    if component_sizes_sorted:\n",
        "        largest_component_label = component_sizes_sorted[0][0]\n",
        "        largest_component_size = component_sizes_sorted[0][1]\n",
        "\n",
        "        # Filter airports belonging to the largest connected component\n",
        "        largest_component_airports = final_labels.filter(lambda x: x[1] == largest_component_label) \\\n",
        "            .map(lambda x: broadcast_id_to_airport.value[x[0]]).collect()\n",
        "    else:\n",
        "        largest_component_label = None\n",
        "        largest_component_size = 0\n",
        "        largest_component_airports = []\n",
        "\n",
        "    return num_connected_components, component_sizes_sorted, largest_component_airports, execution_time\n"
      ],
      "metadata": {
        "id": "5e-uqszV74WY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We execute the connected components analysis on the flight network dataset for the specified date range. The steps include:\n",
        "\n",
        "1. **Defining the Analysis Period:**\n",
        "   - Setting the start and end dates for the analysis.\n",
        "\n",
        "2. **Data Preparation:**\n",
        "   - Converting the `'Fly_date'` column to a proper date format to ensure accurate filtering.\n",
        "\n",
        "3. **Identifying Connected Components:**\n",
        "   - Utilizing the `identify_connected_components_rdd` function to determine the connected components within the defined date range.\n",
        "\n",
        "4. **Displaying the Results:**\n",
        "   - Printing the total number of connected components.\n",
        "   - Listing the sizes of each connected component in descending order.\n",
        "   - Enumerating the airports that belong to the largest connected component.\n",
        "   - Showing the execution time of the analysis.\n"
      ],
      "metadata": {
        "id": "22gDpkG222Mw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XrsbIoiWlV2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c7417e-0958-4956-9cce-d259fdc0e226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1\n",
            "First iteration, no comparison.\n",
            "Iteration 2\n",
            "Differences from the previous iteration: 208\n",
            "Iteration 3\n",
            "Differences from the previous iteration: 16\n",
            "Iteration 4\n",
            "Differences from the previous iteration: 0\n",
            "Convergence achieved.\n"
          ]
        }
      ],
      "source": [
        "# Define the start and end dates for the analysis period\n",
        "start_date = \"2000-01-01\"\n",
        "end_date = \"2000-05-31\"\n",
        "\n",
        "# Convert the 'Fly_date' column to a date type with the specified format\n",
        "#flight_network_df = flight_network_df.withColumn(\"Fly_date\", to_date(col(\"Fly_date\"), \"yyyy-MM-dd\"))\n",
        "\n",
        "# Identify connected components within the specified date range using the previously defined function\n",
        "num_connected_components, component_sizes_sorted, largest_component_airports, execution_time = identify_connected_components_rdd(flight_network_df, start_date, end_date)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results of the connected components analysis\n",
        "print(\"\\n===== Connected Components Analysis =====\\n\")\n",
        "\n",
        "# Print the number of connected components found within the specified date range\n",
        "print(f\"Number of connected components between {start_date} and {end_date}: {num_connected_components}\\n\")\n",
        "\n",
        "# Print the sizes of each connected component, sorted in descending order\n",
        "print(\"Sizes of each connected component (sorted in descending order):\")\n",
        "for idx, (component, size) in enumerate(component_sizes_sorted, start=1):\n",
        "    print(f\"{idx}. Component {component}: {size} airports\")\n",
        "print()\n",
        "\n",
        "# Print the list of airports that belong to the largest connected component\n",
        "print(\"Airports in the largest connected component:\")\n",
        "print(\", \".join(f\"{airport}\" for airport in largest_component_airports))\n",
        "\n",
        "# Print the execution time of the connected components analysis\n",
        "print(f\"Execution time: {execution_time}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osSgt70138lR",
        "outputId": "a0152b3c-416c-4b09-a76b-1cae84a4e215"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Connected Components Analysis =====\n",
            "\n",
            "Number of connected components between 2000-01-01 and 2000-05-31: 2\n",
            "\n",
            "Sizes of each connected component (sorted in descending order):\n",
            "1. Component 0: 298 airports\n",
            "2. Component 227: 2 airports\n",
            "\n",
            "Airports in the largest connected component:\n",
            "IND, JAX, SEA, FOE, JBR, RDU, TYS, EKO, EAT, CWA, IAD, MCO, MSN, SAV, FOD, PIT, BDL, ATL, FSM, DEC, JFK, DTW, BIL, ROC, DRT, ELP, YIP, SYR, JAC, SBP, MSP, BOS, BTR, LNK, DRO, SBA, BTV, SFB, MLU, EYW, TPA, ACT, BRD, ITH, UIN, SAT, CAK, STC, BIS, GUP, FAR, TUS, LCK, LCH, MKL, SHV, JNU, SFO, PWM, ICT, HNL, FLL, BMI, ALO, YUM, LAX, EWR, KTN, OGG, BRL, IAH, MEM, AVL, DHN, MRC, ORD, HLN, CRW, LBL, PAH, LAS, CAE, AZO, CHA, BVX, PBI, GEG, LIT, RST, BYH, ACY, OKC, DFW, MOB, ATY, GPT, RNO, YNG, PIR, CGI, MSY, SLC, SPI, TYR, SLN, GRR, AGS, OAK, EAU, APN, RDD, BLI, FAY, BJI, MMI, GSO, CMH, SMF, GJT, LRD, SAN, MBS, LBB, OGD, PNS, CLT, STL, MAF, TLH, ITO, BGR, RIC, BTM, ABQ, FLO, DCA, CLE, DET, LEX, CPR, SJC, MYR, FNT, ELM, SUX, MSO, ABY, FSD, BFM, AFW, YKM, FCA, MCN, TVC, PFN, PVD, ILM, PHL, GTF, SBN, MIA, SNA, LAN, MZZ, MVN, ABE, BWI, WGO, MCW, ADS, CHS, LGA, GSP, PUB, ADM, MWH, ANC, PIA, GRI, SGF, CVG, BFI, CLM, TUP, ABR, FAI, MHT, TOL, PDK, HYS, BNA, CRP, ESC, ILE, ILG, COU, TUL, LSE, GNV, MHL, MDW, RDM, XNA, CSG, ROA, GRB, BRO, GTR, OSH, PDX, DAL, MKG, VCT, BQK, DAY, CMI, AVP, MTJ, OPF, HOU, PUW, GGG, VLD, LYH, DSM, AMA, ALW, GFK, MQT, SPS, TWF, JAN, EVV, BFL, ABI, PDT, COS, ORH, PHX, BUF, BZN, ACV, LAF, LWS, LFT, BGM, JLN, MUT, FAT, OMA, ATW, PIH, ADQ, GYY, DBQ, SUS, LAW, APF, AUS, RFD, SJT, GRK, MHR, CID, MOT, CLL, MEI, ILN, MKE, MDT, OLS, SYI, NQX, RAP, MGM, BPT, LBF, PGV, HSV, ERI, EFD, MWA, BTL, FWA, TCL, CYS, DLH, TBN, MFR, MCI, CHO, IDA, AEX, ALB, BHM, EUG, LMT, ROW\n",
            "Execution time: 288.752557516098\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Compare the execution time and the results of your implementation with those of the GraphFrames package for identifying connected components. If there is any difference in the results, provide an explanation for why that might occur.\n"
      ],
      "metadata": {
        "id": "3UMWRMEvuuU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a new Spark session configured with GraphFrames to perform connected components analysis on the flight network dataset. This setup enables us to leverage graph-based processing capabilities for a more efficient and comprehensive analysis."
      ],
      "metadata": {
        "id": "MQ5BZFhU3ssq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the active SparkContext instance\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "# Stop the SparkContext if you wish to create a new one\n",
        "sc.stop()\n",
        "\n",
        "# Initialize Spark Session with configurations\n",
        "print(\"Initializing Spark Session...\")\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "        .appName(\"GraphFramesExample\") \\\n",
        "        .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.0-s_2.12\") \\\n",
        "        .config(\"spark.driver.memory\", \"15g\") \\\n",
        "        .config(\"spark.executor.memory\", \"15g\") \\\n",
        "        .config(\"spark.sql.shuffle.partitions\", \"100\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "print(\"... Spark Session Created\")\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CGK0B8bBbGx",
        "outputId": "45c782b2-a0ce-4843-d3be-434b5e0d96be"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Spark Session...\n",
            "... Spark Session Created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading and Preparing the Flight Network Dataset"
      ],
      "metadata": {
        "id": "su99M5By4zPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset as a DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/Airports2.csv')\n",
        "flight_network_df = spark.createDataFrame(df)\n",
        "\n",
        "# Display the schema to confirm\n",
        "flight_network_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_orp8ymoLIQB",
        "outputId": "eecf5d06-5e7d-4d0e-b37b-36518d7a663f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Origin_airport: string (nullable = true)\n",
            " |-- Destination_airport: string (nullable = true)\n",
            " |-- Origin_city: string (nullable = true)\n",
            " |-- Destination_city: string (nullable = true)\n",
            " |-- Passengers: long (nullable = true)\n",
            " |-- Seats: long (nullable = true)\n",
            " |-- Flights: long (nullable = true)\n",
            " |-- Distance: long (nullable = true)\n",
            " |-- Fly_date: string (nullable = true)\n",
            " |-- Origin_population: long (nullable = true)\n",
            " |-- Destination_population: long (nullable = true)\n",
            " |-- Org_airport_lat: double (nullable = true)\n",
            " |-- Org_airport_long: double (nullable = true)\n",
            " |-- Dest_airport_lat: double (nullable = true)\n",
            " |-- Dest_airport_long: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the `identify_connected_components_graphframes` function, which leverages GraphFrames to identify connected components within the flight network dataset over a specified date range. This function filters the relevant flight data, constructs a graph of airports, computes the connected components, and returns key metrics such as the number of connected components, their sizes, the airports in the largest connected component, and the execution time of the analysis.\n"
      ],
      "metadata": {
        "id": "VihBLv2V5C4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from graphframes import GraphFrame\n",
        "\n",
        "def identify_connected_components_graphframes(flight_network_df, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Identifies the connected components in the flight network between start_date and end_date using GraphFrames.\n",
        "\n",
        "    Parameters:\n",
        "    - flight_network_df (DataFrame): Spark DataFrame containing flight data with columns\n",
        "                                     'Origin_airport', 'Destination_airport', 'Fly_date'.\n",
        "    - start_date (str): Start date of the period in 'YYYY-MM-DD' format.\n",
        "    - end_date (str): End date of the period in 'YYYY-MM-DD' format.\n",
        "\n",
        "    Returns:\n",
        "    - num_connected_components (int): Number of connected components.\n",
        "    - component_sizes_sorted (list of tuples): List of component sizes sorted in descending order.\n",
        "    - largest_component_airports (list): List of airports in the largest connected component.\n",
        "    - execution_time (float): Execution time in seconds.\n",
        "    \"\"\"\n",
        "\n",
        "    # Filter flights within the specified date range and drop rows with null airports\n",
        "    filtered_df = flight_network_df.filter(\n",
        "        (col(\"Fly_date\") >= start_date) & (col(\"Fly_date\") <= end_date)\n",
        "    ).na.drop(subset=[\"Origin_airport\", \"Destination_airport\"])\n",
        "\n",
        "    # Prepare vertices by selecting unique origin and destination airports\n",
        "    vertices = filtered_df.select(col(\"Origin_airport\").alias(\"id\")).union(\n",
        "        filtered_df.select(col(\"Destination_airport\").alias(\"id\"))\n",
        "    ).distinct()\n",
        "\n",
        "    # Prepare edges by selecting unique pairs of origin and destination airports\n",
        "    edges = filtered_df.select(\n",
        "        col(\"Origin_airport\").alias(\"src\"),\n",
        "        col(\"Destination_airport\").alias(\"dst\")\n",
        "    ).distinct()\n",
        "\n",
        "    # Create the GraphFrame using the vertices and edges\n",
        "    g = GraphFrame(vertices, edges)\n",
        "\n",
        "    # Start the timer to measure execution time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Compute the connected components using GraphFrame's connectedComponents method\n",
        "    result_graphframes = g.connectedComponents()\n",
        "\n",
        "    # Stop the timer and calculate the execution time\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "\n",
        "    # Count the number of distinct connected components\n",
        "    num_components = result_graphframes.select(\"component\").distinct().count()\n",
        "\n",
        "    # Count the number of airports in each connected component and sort them in descending order\n",
        "    component_sizes = result_graphframes.groupBy(\"component\").count().orderBy(\"count\", ascending=False).collect()\n",
        "    component_sizes_sorted = [(row[\"component\"], row[\"count\"]) for row in component_sizes]\n",
        "\n",
        "    # Identify the largest connected component based on the sorted component sizes\n",
        "    if component_sizes_sorted:\n",
        "        largest_component_label = component_sizes_sorted[0][0]\n",
        "        largest_component_size = component_sizes_sorted[0][1]\n",
        "\n",
        "        # Filter airports that belong to the largest connected component\n",
        "        largest_component_airports = result_graphframes.filter(\n",
        "            col(\"component\") == largest_component_label\n",
        "        ).select(\"id\").rdd.map(lambda row: row[\"id\"]).collect()\n",
        "    else:\n",
        "        largest_component_label = None\n",
        "        largest_component_size = 0\n",
        "        largest_component_airports = []\n",
        "\n",
        "    return num_components, component_sizes_sorted, largest_component_airports, execution_time"
      ],
      "metadata": {
        "id": "TDiBLH3aAkXI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We execute the connected components analysis on the flight network dataset for the specified date range. The steps include:\n",
        "\n",
        "1. **Defining the Analysis Period:**\n",
        "   - Setting the start and end dates for the analysis.\n",
        "\n",
        "2. **Data Preparation:**\n",
        "   - Converting the `'Fly_date'` column to a proper date format to ensure accurate filtering.\n",
        "\n",
        "3. **Identifying Connected Components:**\n",
        "   - Utilizing the `identify_connected_components_graphframes` function to determine the connected components within the defined date range.\n",
        "\n",
        "4. **Displaying the Results:**\n",
        "   - Printing the total number of connected components.\n",
        "   - Listing the sizes of each connected component in descending order.\n",
        "   - Enumerating the airports that belong to the largest connected component.\n",
        "   - Showing the execution time of the analysis.\n"
      ],
      "metadata": {
        "id": "4f-H27Py_uTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the date range for analysis\n",
        "start_date = \"2000-01-01\"  # The start date for filtering flight data\n",
        "end_date = \"2000-05-31\"    # The end date for filtering flight data\n",
        "\n",
        "# Call the function to identify connected components within the specified date range using graphframes\n",
        "num_connected_components, component_sizes_sorted, largest_component_airports, execution_time = identify_connected_components_graphframes(\n",
        "    flight_network_df, start_date, end_date\n",
        ")\n",
        "\n",
        "# Print the analysis results\n",
        "\n",
        "print(\"\\n===== Connected Components Analysis =====\\n\")\n",
        "\n",
        "# Display the total number of connected components identified within the specified date range\n",
        "print(f\"Number of connected components between {start_date} and {end_date}: {num_connected_components}\\n\")\n",
        "\n",
        "# Print the sizes of each connected component, sorted from largest to smallest\n",
        "print(\"Sizes of each connected component (sorted in descending order):\")\n",
        "for idx, (component, size) in enumerate(component_sizes_sorted, start=1):\n",
        "    print(f\"{idx}. Component {component}: {size} airports\")\n",
        "print()\n",
        "\n",
        "# Print the list of airports that belong to the largest connected component\n",
        "print(\"Airports in the largest connected component:\")\n",
        "print(\", \".join(f\"{airport}\" for airport in largest_component_airports))\n",
        "\n",
        "# Display the total time taken to perform the connected components analysis\n",
        "print(f\"Execution time: {execution_time} seconds\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "wjKroI1rJXx5",
        "outputId": "dda2d313-a218-498d-ee55-9cdb9bbe2ac4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling o1905.loadClass.\n: java.lang.ClassNotFoundException: org.graphframes.GraphFramePythonAPI\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-26626629f4e9>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Call the function to identify connected components within the specified date range using graphframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m num_connected_components, component_sizes_sorted, largest_component_airports, execution_time = identify_connected_components_graphframes(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mflight_network_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-18-8ba826dcb125>\u001b[0m in \u001b[0;36midentify_connected_components_graphframes\u001b[0;34m(flight_network_df, start_date, end_date)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Create the GraphFrame using the vertices and edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Start the timer to measure execution time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/graphframes/graphframe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, v, e)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sqlContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm_gf_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_java_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm_gf_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/graphframes/graphframe.py\u001b[0m in \u001b[0;36m_java_api\u001b[0;34m(jsc)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_java_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mjavaClassName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"org.graphframes.GraphFramePythonAPI\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetContextClassLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjavaClassName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mnewInstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1905.loadClass.\n: java.lang.ClassNotFoundException: org.graphframes.GraphFramePythonAPI\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, the analysis using GraphFrames cannot be completed because the graphframes package was not successfully imported. Despite configuring the Spark session with the appropriate package\n",
        "\n",
        "```python\n",
        ".config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.4-s_2.12\")\n",
        "```\n",
        "the package fails to initialize properly, likely due to compatibility issues, unresolved dependencies and limitations of the runtime environment. As a result, we are unable to perform the requested analysis to identify the connected components of the flight network using GraphFrames.\n"
      ],
      "metadata": {
        "id": "siP9kK3em_MY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qF4DBjclV2v"
      },
      "source": [
        "## Algorithmic Question (AQ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTCtca1xlV2x",
        "outputId": "ee27fc0d-365c-4ae7-a016-b93b1c7ec599"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'functions' from 'c:\\\\Users\\\\marta\\\\OneDrive\\\\Documenti\\\\GitHub\\\\ADM_HW5\\\\functions.py'>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import importlib, functions\n",
        "importlib.reload(functions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ona0Ys-YlV2x"
      },
      "source": [
        "### a) Write a pseudocode that describes the algorithm to find the cheapest route with at most k stops.\n",
        "\n",
        "---\n",
        "\n",
        "**Function**: $createAdjacencyList(flights, n)$\n",
        "\n",
        "**Input**:\n",
        "- $flights$: A list of edges in the form $[u, v, \\text{cost}]$, where:\n",
        "  - $u\\in V$: The *source vertex*;\n",
        "  - $v\\in V$: The *destination vertex*;\n",
        "  - $cost$: The *weight of the edge* from $u$ to $v$.\n",
        "- $n$: The *total number of vertices* in the graph.\n",
        "\n",
        "**Output**: An *adjacency list* where each vertex $u$ is associated with a list of lists $[v, cost]$.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;$adj\\_list$ &larr; **initialize** list of empty lists of size $n$\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**for each** flight $[u, v, cost]$ **in** $flights$ **do**\\\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**add** $[v, cost]$ **to** $adj\\_list[u]$\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**return** $adj\\_list$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Function**: $minCostWithMaxKEdgesDFS(G, currentNode, destination, maxStops, currentCost, minCostSoFar, visitedNodes)$\n",
        "\n",
        "**Input**:\n",
        "- $G = (V, E)$: Graph in *adjacency-list representation*;\n",
        "- $currentNode \\in V$: The *current vertex* being explored;\n",
        "- $destination \\in V$: The *destination vertex*;\n",
        "- $maxStops$: The *maximum number of stops allowed*;\n",
        "- $currentCost$: The *cumulative cost of the path so far*;\n",
        "- $minCostSoFar$: The *minimum cost found so far*;\n",
        "- $visitedNodes$: The set of distinct nodes already visited in the current DFS path.\n",
        "\n",
        "**Output**: The *updated minimum cost to travel from* $currentNode$ *to* $destination$ *within paths that include at most* $maxStops+1$ *nodes*.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**if** $currentNode == destination$ **then**:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**return** $\\mathbf{min}(currentCost, minCostSoFar)$  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**if** $maxStops < 0$ **then**:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**return** $minCostSoFar$  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**add** $currentNode$ to $visitedNodes$  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**for each** *list* $[neighbor, edgeCost]$ **in** $G[currentNode]$ **do**:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**if** $neighbor \\notin visitedNodes$ **and** $currentCost + edgeCost < minCostSoFar$ **then**:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$updatedMinCost$ &larr; $\\mathbf{minCostWithMaxKEdgesDFS}(G, neighbor, destination, maxStops - 1, currentCost + edgeCost, minCostSoFar, visitedNodes)$  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**remove** $currentNode$ from $visitedNodes$  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**return** $updatedMinCost$\n",
        "\n",
        "---\n",
        "**Function**: $findCheapestRouteDFS(n, flights, src, dest, k)$\n",
        "\n",
        "**Input**:\n",
        "- $n$: The *total number of vertices* in the graph.\n",
        "- $flights$: A list of edges in the form $[u, v, cost]$, where:\n",
        "  - $u$: The *source vertex*;\n",
        "  - $v$: The *destination vertex*;\n",
        "  - $cost$: *weight of the edge* from $u$ to $v$.\n",
        "- $src \\in V$: The *source vertex*;\n",
        "- $dst\\in V$: The *destination vertex*;\n",
        "- $k$: The *maximum number of edges allowed*.\n",
        "\n",
        "**Output**: The *minimum cost* to travel from $src$ to $dst$ crossing at the most $k$ edges, or $-1$ if no valid path exists.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;$G$ &larr; $\\mathbf{createAdjacencyList}(flights, n)$\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;$min\\_cost$ &larr; $\\mathbf{minCostWithMaxKEdgesDFS}(G, src, dst, k, 0, \\infty, \\emptyset)$\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**if** $min\\_cost < \\infty$ **then**\\\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**return** $min\\_cost$\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**return** $-1$\n",
        "\n",
        "#### Correctness analysis\n",
        "\n",
        "The algorithm systematically explores all possible simple paths from the source to the destination whose length does not exceed $k+1$ nodes. First, the graph is transformed into an adjacency list via $\\mathbf{createAdjacencyList}$, ensuring that for every node, we know all its outgoing edges and the corresponding costs. During the depth-first search in $\\mathbf{minCostWithMaxKEdgesDFS}$, each recursive call only proceeds if the number of remaining stops is non-negative, thereby enforcing the constraint that no path longer than $k+1$ nodes (i.e., $k$ edges) is explored. Whenever the current node matches the destination, the minimum cost so far is updated if the current path’s cost is lower, so the global minimum for paths of acceptable length is eventually discovered. In addition, the algorithm temporarily includes the current node in the set of visited nodes to prevent revisiting the same node within one path, then removes it upon returning from the recursion, thereby considering only simple paths. This ensures no cycles inflate the cost or cause infinite recursion. Hence, by the time $\\mathbf{minCostWithMaxKEdgesDFS}$ completes, it has exhaustively checked all valid simple paths of length at most $k+1$ nodes and recorded the cheapest among them; if no such path exists, the function returns $\\infty$, causing the top-level $\\mathbf{findCheapestRouteDFS}$ to return $-1$. Thus, the algorithm correctly identifies either the minimal cost or the impossibility of reaching the destination under the specified constraints.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TgKi2A3lV2y"
      },
      "source": [
        "### b) Implement the algorithm in Python and simulate the given test cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE4sMEsRlV2y"
      },
      "source": [
        "We have implemented the `find_cheapest_route_DFS` main function, along with its helper routines `create_adjacency_list` and `min_cost_with_max_K_edges_DFS`, in the `functions.py` module. For a more in-depth explanation of how these functions work, please refer to the detailed comments included there. Below, we call `find_cheapest_route_DFS` on the provided test cases and verify that it returns the expected results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBEkdJcAlV2y",
        "outputId": "2b379ee4-16a5-4f6e-9805-12fa63764216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flights: [[0, 1, 100], [1, 2, 100], [2, 0, 100], [1, 3, 600], [2, 3, 200]], source: 0, destination: 3, maximum number of stops: 1\n",
            "Cheapest route: 700\n",
            "\n",
            "Flights: [[0, 1, 100], [1, 2, 100], [0, 2, 500]], source: 0, destination: 2, maximum number of stops: 1\n",
            "Cheapest route: 200\n",
            "\n",
            "Flights: [[0, 1, 100], [1, 2, 100], [0, 2, 500]], source: 0, destination: 2, maximum number of stops: 0\n",
            "Cheapest route: 500\n",
            "\n",
            "Flights: [[0, 1, 100], [0, 2, 200], [1, 3, 300], [2, 3, 300]], source: 0, destination: 3, maximum number of stops: 2\n",
            "Cheapest route: 400\n",
            "\n",
            "Flights: [[0, 1, 100], [0, 2, 200], [1, 3, 300], [2, 3, 200]], source: 0, destination: 3, maximum number of stops: 2\n",
            "Cheapest route: 400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from functions import find_cheapest_route_DFS\n",
        "\n",
        "n = [4, 3, 3, 4, 4]\n",
        "flights = [[[0, 1, 100], [1, 2, 100], [2, 0, 100], [1, 3, 600], [2, 3, 200]],\n",
        "           [[0, 1, 100], [1, 2, 100], [0, 2, 500]],\n",
        "           [[0, 1, 100], [1, 2, 100], [0, 2, 500]],\n",
        "           [[0, 1, 100], [0, 2, 200], [1, 3, 300], [2, 3, 300]],\n",
        "           [[0, 1, 100], [0, 2, 200], [1, 3, 300], [2, 3, 200]]]\n",
        "src = [0, 0, 0, 0, 0]\n",
        "dst = [3, 2, 2, 3, 3]\n",
        "k = [1, 1, 0, 2, 2]\n",
        "\n",
        "for i in range(len(n)):\n",
        "    result = find_cheapest_route_DFS(n[i], flights[i], src[i], dst[i], k[i])\n",
        "    print(\"Flights: \" + str(flights[i]) +\n",
        "          \", source: \" + str(src[i]) +\n",
        "          \", destination: \" + str(dst[i]) +\n",
        "          \", maximum number of stops: \" + str(k[i]) +\n",
        "          \"\\nCheapest route: \" + str(result) + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaE8vV1GlV2y"
      },
      "source": [
        "### c) Analyze the algorithm's efficiency. Provide its time complexity and space complexity, and explain whether it is efficient for large graphs (e.g., n > 100).\n",
        "\n",
        "#### Time Complexity Analysis\n",
        "The main algorithm is $\\mathbf{findCheapestRouteDFS}$, whose complexity depends on the algorithms $\\mathbf{createAdjacencyList}$ and $\\mathbf{minCostWithMaxKEdgesDFS}$. Let us analyze their contributions in detail.\n",
        "\n",
        "The algorithm $\\mathbf{createAdjacencyList}$ constructs the graph representation using an adjacency list. It initializes an empty list for each of the $n$ nodes, which takes $O(n)$, and iterates over all $m$ edges to populate the adjacency list, requiring $O(m)$. Therefore, the complexity of $\\mathbf{createAdjacencyList}$ is $O(m + n)$.\n",
        "\n",
        "The computationally intensive part is the algorithm $\\mathbf{minCostWithMaxKEdgesDFS}$, which performs a depth-first search (DFS) with a constraint on the maximum number of stops $k$. The algorithm explores all possible simple paths (i.e., crossing each node in the path exactly once) starting from $src$, and the maximum depth of the recursion is $k+1$ (corresponding to $k$ stops). Importantly, the algorithm does not only visit paths of length $k+1$ but also considers paths of smaller lengths when the condition $src == dst$ is satisfied before reaching the $k$-stop limit.\n",
        "\n",
        "To analyze its complexity, let us determine the number of recursive calls. At each level of recursion, the DFS explores all neighbors of the current node. Let $G=(V,E)$ be the graph built by $\\mathbf{createAdjacencyList}$, where $n=|V|$ and $m=|E|$. In the worst case, the graph is complete, meaning there exists an edge between each pair of distinct nodes, resulting in $deg(u)=n-1 \\; \\forall u \\in V$ and $m = \\dfrac{n(n-1)}{2}$.\n",
        "\n",
        "Moreover, in the worst case, the algorithm analyzes all possible simple paths of length $k+1$ starting from the source node, with the condition $src == dst$ being satisfied only when the stops finish or never. Let us analyze the time complexity in the worst case. The first call inserts $src$ into $visitedNodes$ and generates $n-1$ calls. Each of these generates $n-2$ calls at the next level, which in turn generate $n-3$ calls, and so on, until the $(k+1)^{th}$ level. At this depth, the algorithm generates the final recursive calls, with the branching factor reduced to $n-k-1$. This occurs because $visitedNodes$ at each call contains the nodes previously visited for the specific path, avoiding revisits and ensuring the algorithm explores only simple paths of length at most $k+1$. When a recursive call ends, it removes the specific $src$ from $visitedNodes$, allowing backtracking. Thus, the number of recursive calls $T(n, k)$ can be expressed as:\n",
        "\n",
        "\\begin{align*}\n",
        "T(n,k) &= (n-1) + (n-1)(n-2) + (n-1)(n-2)(n-3) + \\dots + (n-1)(n-2)\\cdots(n-k)(n-k-1) = \\sum_{i=1}^{k+1} \\prod_{j=0}^{i-1} (n-1-j)\n",
        "\\end{align*}\n",
        "\n",
        "To simplify, we estimate an upper bound:\n",
        "\\begin{equation*}\n",
        "T(n,k) \\leq \\sum_{i=1}^{k+1} (n-1)^i.\n",
        "\\end{equation*}\n",
        "\n",
        "The summation represents a geometric progression with ratio $(n-1)$. The closed form for this summation is:\n",
        "\\begin{align*}\n",
        "T(n,k) &\\leq \\dfrac{(n-1)^{k+2} - (n-1)}{n-2} \\approx (n-1)^{k+1}\n",
        "\\end{align*}\n",
        "\n",
        "This simplifies asymptotically to:\n",
        "\\begin{equation*}\n",
        "T(n,k) \\in O((n-1)^{k+1}).\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the overall time complexity of $\\mathbf{findCheapestRouteDFS}$ is $O(m + (n-1)^{k+1})$, where $m$ is the number of edges and $(n-1)^{k+1}$ is the dominating term in the worst-case scenario.\n",
        "\n",
        "#### Space Compelxity Analysis\n",
        "When analyzing the space complexity of $\\mathbf{findCheapestRouteDFS}$, we take into account the adjacency list used to represent the graph, the recursive call stack, and the auxiliary data structures required during execution. The graph itself is stored using an adjacency list that requires $O(n + m)$ space.\n",
        "\n",
        "Beyond the space needed to store the input graph, the algorithm uses additional memory for the recursion and for tracking visited nodes in the current path. The recursive call stack can grow up to a depth of $k+1$ calls, where $k$ is the maximum number of stops allowed. Consequently, the worst-case space usage for the call stack is $O(k)$. In parallel, the set of visited nodes holds at most $k+1$ distinct vertices at any point, adding another $O(k)$ to the total auxiliary space.\n",
        "\n",
        "Combining these factors, we see that the total space consumption can be expressed as $O(k) + O(k) + O(n + m)$, which simplifies to $O(k + n + m)$. Since in the worst case $k$ can be bounded by $n$, this further reduces to $O(n + m)$. Therefore, if we consider only the additional space used during the DFS (beyond the input), it is $O(k)$. However, when we include the adjacency list needed to store the graph, the overall space complexity is $O(n + m)$.\n",
        "\n",
        "\n",
        "#### Efficiency for large graphs\n",
        "The efficiency of $\\mathbf{findCheapestRouteDFS}$ for large graphs is significantly influenced by the structure of the graph and the parameter $k$, which limits the maximum number of stops. While the adjacency list construction is efficient, taking $O(m + n)$, the depth-first search component introduces exponential growth due to the $(n-1)^{k+1}$ term in its time complexity.\\\n",
        "For sparse graphs, where the number of edges $m$ is close to $n$, and for small values of $k$, the algorithm can handle larger graphs effectively because the exponential term $(n-1)^{k+1}$ remains manageable. However, as $k$ increases, or if the graph is dense ($m \\approx n^2$), the number of paths the DFS must explore grows rapidly, making the algorithm impractical for large graphs.\\\n",
        "In summary, while the algorithm is suitable for small $k$ and sparse graphs, it is not efficient for large graphs with high connectivity or large $k$, as the exponential growth dominates the computational cost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40yRmyL1lV2z"
      },
      "source": [
        "### d) Optimize the algorithm to handle larger graphs. Provide an updated pseudocode and analyze the computational complexity of your optimization.\n",
        "---\n",
        "**Function**: $minCostWithMaxKEdgesPol(G, src, dst, k)$\n",
        "\n",
        "**Input**:\n",
        "- $G = (V, E)$: Graph in *adjacency-list representation*;\n",
        "- $src \\in V$: The *source vertex*;\n",
        "- $dst \\in V$: The *destination vertex*;\n",
        "- $k$: The *maximum number of edges allowed*.\n",
        "\n",
        "**Output**: The *minimum cost to travel from* $src$ *to* $dst$ *using at most* $k+1$ *edges, or* $\\infty$ *if no valid path exists*.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp; $numNodes$ &larr; $\\mathbf{len}(V)$  \n",
        "&nbsp;&nbsp;&nbsp; $INF$ &larr; $\\infty$  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp; **Initialize** $minCostPerEdge[i][v]$ for all $i \\in [0, k+1]$ and $v \\in V$:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $minCostPerEdge[i][v]$ &larr; $INF$  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;$minCostPerEdge[0][src]$ &larr; $0$  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp; **for each** $edgeCount \\in [1, k+1]$ **do**:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $minCostPerEdge[edgeCount][.]$ &larr; $minCostPerEdge[edgeCount-1][.]$  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **for each** vertex $u \\in V$:\\\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **if** $minCostPerEdge[edgeCount-1][u] \\neq \\infty$ **then**:  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **for each** $(v, weight) \\in G[u]$ **do**:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$newCost$ &larr; $minCostPerEdge[edgeCount-1][u] + weight$  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **if** $newCost < minCostPerEdge[edgeCount][v]$ **then**:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$minCostPerEdge[edgeCount][v]$ &larr; $newCost$  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp; **return** $\\mathbf{min}(minCostPerEdge[edgeCount][dst] \\, \\forall \\, edgeCount \\in [0, k+1])$\n",
        "\n",
        "---\n",
        "**Function**: $findCheapestRoutePol(n, flights, src, dest, k)$\n",
        "\n",
        "**Input**:\n",
        "- $n$: The *total number of vertices* in the graph.\n",
        "- $flights$: A list of edges in the form $[u, v, cost]$, where:\n",
        "  - $u$: The *source vertex*;\n",
        "  - $v$: The *destination vertex*;\n",
        "  - $cost$: *weight of the edge* from $u$ to $v$.\n",
        "- $src \\in V$: The *source vertex*;\n",
        "- $dst\\in V$: The *destination vertex*;\n",
        "- $k$: The *maximum number of edges allowed*.\n",
        "\n",
        "**Output**: The *minimum cost* to travel from $src$ to $dst$ crossing at the most $k$ edges, or $-1$ if no valid path exists.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp; $G$ &larr; $\\mathbf{createAdjacencyList}(flights, n)$\n",
        "\n",
        "&nbsp;&nbsp;&nbsp; $min\\_cost$ &larr; $\\mathbf{minCostWithMaxKEdgesPol}(G, src, dst, k)$\n",
        "\n",
        "&nbsp;&nbsp;&nbsp; **if** $min\\_cost < \\infty$ **then**\\\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; **return** $min\\_cost$\n",
        "\n",
        "&nbsp;&nbsp;&nbsp; **return** $-1$\n",
        "\n",
        "---\n",
        "\n",
        "#### Correctness Analysis\n",
        "This approach relies on a dynamic-programming-like strategy to compute the minimum cost of reaching each vertex using up to $k+1$ edges. The array $minCostPerEdge[i][v]$ stores the minimal cost to reach vertex $v$ with exactly $i$ edges, and it is initialized to infinity for all $i$ and $v$, except for $minCostPerEdge[0][src]$ which is set to $0$. On each iteration from $1$ to $k+1$, the values of $minCostPerEdge[i]$ are first copied from $minCostPerEdge[i-1]$, which ensures that no vertex’s cost worsens from one step to the next. The algorithm then looks at each vertex $u$ for which $minCostPerEdge[i-1][u]$ is not infinity, and examines every edge $(u \\rightarrow v)$ with weight $weight$. If traveling from $src$ to $u$ with $i-1$ edges costs $minCostPerEdge[i-1][u]$ and then continuing to $v$ adds $weight$, the new total cost $newCost$ is compared to the current $minCostPerEdge[i][v]$. If $newCost$ is smaller, $minCostPerEdge[i][v]$ is updated. By the end of these $k+1$ rounds, $minCostPerEdge[i][v]$ will hold the lowest possible cost from $src$ to $v$ with at most $i$ edges. The minimum across all $i \\in [0, k+1]$ for the destination $dst$ thus reflects the true minimal cost to get from $src$ to $dst$ with at most $k+1$ edges. If no cost was ever improved from infinity, then it follows that no valid path with at most $k$ edges (or $k+1$ nodes) exists, and $\\infty$ is returned. Hence the algorithm correctly finds the cheapest cost under the given edge constraint, or deduces that no such route is possible.\n",
        "\n",
        "\n",
        "#### Time Complexity Analysis\n",
        "The function $\\mathbf{createAdjacencyList(flights, n)}$ is the same as previously discussed, used for building the adjacency list representation of the graph. Its time complexity is $O(m+n)$, where $m$ is the number of edges and $n$ is the number of nodes. The overall time complexity of the $\\mathbf{findCheapestRoutePol}$ algorithm is determined by the combination of $\\mathbf{createAdjacencyList}$ and $\\mathbf{minCostWithMaxKEdgesPol}$.\n",
        "\n",
        "Analyzing the $\\mathbf{minCostWithMaxKEdgesPol}$ function in detail, we first compute the number of nodes, which takes $O(n)$. Then, initializing the matrix $minCostPerEdge$ to represent the minimum cost for each node and edge count requires $O(n \\cdot k)$, since the matrix has dimensions $(k+2) \\times n$. Setting $minCostPerEdge[0][src]$ to zero is a single operation and takes $O(1)$.\n",
        "\n",
        "The primary computational effort lies in the nested loops. The outer loop iterates over the number of edge counts, from $1$ to $k+1$, resulting in $O(k)$ iterations. For each iteration, the previous row of the matrix is copied to the current row, which takes $O(n)$. Inside this loop, we iterate over all nodes, amounting to $O(n)$ operations for the middle loop. For each node, we then iterate over its neighbors, and in the worst case, where the graph is complete, each node has up to $n-1$ neighbors. Thus, the inner-most loop processes all neighbors and, when combined with the middle loop, results in $O(n^2)$ operations for each iteration of the outer loop.\n",
        "\n",
        "Given that the outer loop runs $O(k)$ times, the total time complexity of the nested loops can be expressed as:\n",
        "\\begin{align*}\n",
        "T(n, k) = O(k) \\cdot O(n^2) = O(k \\cdot n^2).\n",
        "\\end{align*}\n",
        "\n",
        "After the nested loops complete, the algorithm computes the minimum cost among all valid edge counts from $0$ to $k+1$. This requires iterating over $k+2$ values and takes $O(k)$.\n",
        "\n",
        "Combining all these components, the total time complexity of $\\mathbf{minCostWithMaxKEdgesPol}$ is $O(k \\cdot n^2)$. As $O(k \\cdot n^2)$ dominates, it determines the overall time complexity of the $\\mathbf{findCheapestRoutePol}$ algorithm, exceeding the $O(m+n)$ complexity of creating the adjacency list.\n",
        "\n",
        "#### Space Complexity Analysis\n",
        "The space complexity of the $\\mathbf{minCostWithMaxKEdgesPol}$ algorithm is primarily determined by the $minCostPerEdge$ matrix, which has dimensions $(k+2) \\times n$. Thus, the space complexity is $O(k \\cdot n)$. No additional significant memory is used apart from a few variables for computation, making the space usage manageable for most practical cases. Considering the memory required to store the graph's adjacency list representation, the total space complexity of $\\mathbf{findCheapestRoutePol}$ is $O(k \\cdot n + m)$.\n",
        "\n",
        "#### Efficiency for large graphs\n",
        "The $\\mathbf{minCostWithMaxKEdgesPol}$ algorithm is significantly more efficient in terms of time complexity compared to the DFS-based algorithm used previously. The DFS-based approach explores all possible paths with up to $k+1$ nodes, leading to an exponential time complexity of $O((n-1)^{k+1})$ in the worst case, as it examines a vast number of potential combinations of nodes. In contrast, $\\mathbf{minCostWithMaxKEdgesPol}$ employs a dynamic programming approach with a time complexity of $O(k \\cdot n^2)$ or equivalently $O(k \\cdot (n + m))$. This improvement is substantial, particularly for large graphs where $n$ and $m$ are significant. The quadratic dependency on $n$ ensures that the algorithm scales better, even for large $k$, making it far more practical for real-world applications.\n",
        "\n",
        "In terms of memory usage, the DFS-based algorithm is more efficient. Disregarding the memory required for the graph's representation, the DFS approach requires $O(k)$ space for the recursive stack and the visited set. On the other hand, $\\mathbf{minCostWithMaxKEdgesPol}$ uses $O(k \\cdot n)$ space to store the dynamic programming matrix $minCostPerEdge$, which grows linearly with both $k$ and $n$. While this increased memory usage might appear to be a disadvantage, the trade-off is worthwhile in this context.\n",
        "\n",
        "In computational problems like these, reducing the time complexity is often far more critical than minimizing memory usage. A faster algorithm enables the solution of larger and more complex instances within a reasonable time frame, which is essential for practical applications. While memory efficiency is important, modern computational systems generally have sufficient memory to handle the $O(k \\cdot n)$ requirement of this algorithm, especially when $k$ and $n$ are not excessively large.\n",
        "\n",
        "Therefore, the $\\mathbf{minCostWithMaxKEdgesPol}$ algorithm strikes a better balance between time and space efficiency, making it a superior choice for solving this problem, especially for large graphs or higher values of $k$. Sacrificing a modest increase in memory for a dramatic improvement in runtime is the more practical trade-off in this scenario.\n",
        "\n",
        "#### Python Implementation\n",
        "We have implemented the `find_cheapest_route_pol` function, which invokes `create_adjacency_list` and the dynamic-programming-based routine `min_cost_with_max_K_edges_pol`, in the `functions.py` module. We used the same test cases as before, and the function produced the same correct results, confirming its validity. For a more detailed explanation, please refer to `functions.py`, where the code is enriched with extensive comments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLoAM9x_lV2z",
        "outputId": "7757921f-ad7c-46d4-b729-1ea8bfcf9c84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flights: [[0, 1, 100], [1, 2, 100], [2, 0, 100], [1, 3, 600], [2, 3, 200]], source: 0, destination: 3, maximum number of stops: 1\n",
            "Cheapest route: 700\n",
            "\n",
            "Flights: [[0, 1, 100], [1, 2, 100], [0, 2, 500]], source: 0, destination: 2, maximum number of stops: 1\n",
            "Cheapest route: 200\n",
            "\n",
            "Flights: [[0, 1, 100], [1, 2, 100], [0, 2, 500]], source: 0, destination: 2, maximum number of stops: 0\n",
            "Cheapest route: 500\n",
            "\n",
            "Flights: [[0, 1, 100], [0, 2, 200], [1, 3, 300], [2, 3, 300]], source: 0, destination: 3, maximum number of stops: 2\n",
            "Cheapest route: 400\n",
            "\n",
            "Flights: [[0, 1, 100], [0, 2, 200], [1, 3, 300], [2, 3, 200]], source: 0, destination: 3, maximum number of stops: 2\n",
            "Cheapest route: 400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from functions import find_cheapest_route_pol\n",
        "\n",
        "n = [5, 3, 3, 4, 4]\n",
        "flights = [[[0, 1, 100], [1, 2, 100], [2, 0, 100], [1, 3, 600], [2, 3, 200]],\n",
        "           [[0, 1, 100], [1, 2, 100], [0, 2, 500]],\n",
        "           [[0, 1, 100], [1, 2, 100], [0, 2, 500]],\n",
        "           [[0, 1, 100], [0, 2, 200], [1, 3, 300], [2, 3, 300]],\n",
        "           [[0, 1, 100], [0, 2, 200], [1, 3, 300], [2, 3, 200]]]\n",
        "src = [0, 0, 0, 0, 0]\n",
        "dst = [3, 2, 2, 3, 3]\n",
        "k = [1, 1, 0, 2, 2]\n",
        "\n",
        "for i in range(len(n)):\n",
        "    result = find_cheapest_route_pol(n[i], flights[i], src[i], dst[i], k[i])\n",
        "    print(\"Flights: \" + str(flights[i]) +\n",
        "          \", source: \" + str(src[i]) +\n",
        "          \", destination: \" + str(dst[i]) +\n",
        "          \", maximum number of stops: \" + str(k[i]) +\n",
        "          \"\\nCheapest route: \" + str(result) + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VGLFIjylV2z"
      },
      "source": [
        "### e) Ask LLM (e.g., ChatGPT) for an optimized version of your algorithm. Compare its solution to yours in terms of performance, time complexity, and correctness.\n",
        "\n",
        "We requested ChatGPT to provide an optimized version of the $\\mathbf{minCostWithMaxKEdgesPol}$ algorithm, and it returned a solution that adapts Dijkstra’s approach by restricting paths to at most $k+1$ flights. The graph is represented as an adjacency list, constructed using the same $\\mathbf{createAdjacencyList}$ function referenced in the earlier pseudocode scripts. Below is the pseudocode that captures ChatGPT’s idea, employing a priority queue to find the cheapest route under the given stop constraint.\n",
        "\n",
        "---\n",
        "**Function**: $findMinCostDijkstra(G, src, dst, k)$\n",
        "\n",
        "**Input**:\n",
        "- $G = (V, E)$: Graph in *adjacency-list representation*;\n",
        "- $src \\in V$: The *source vertex*;\n",
        "- $dst \\in V$: The *destination vertex*;\n",
        "- $k$: The *maximum number of stops allowed*.\n",
        "\n",
        "**Output**: The *minimum cost to travel from* $src$ *to* $dst$ *within paths that include at most* $k+1$ *nodes*.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**for each** vertex $node \\in V$:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$minDistanceK[node]$ &larr; $\\infty$  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp; $minDistanceK[src]$ &larr; 0  \n",
        "&nbsp;&nbsp;&nbsp; $priority\\_queue$ &larr; $\\emptyset$  \n",
        "&nbsp;&nbsp;&nbsp; $priority\\_queue.\\mathbf{insert}((0, src, 0, \\{src\\}))$  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**while** \\(**not** $priority\\_queue.\\mathbf{isEmpty()}$\\) **do**:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $current\\_node, current\\_cost, current\\_stops, current\\_visited$ &larr; $priority\\_queue.\\mathbf{deleteMin()}$  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**if** $current\\_stops \\leq k+1$ **then**:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**if** $current\\_node == dst$ **then**:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$minDistanceK[dst]$ &larr; $current\\_cost$  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**break**  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**for each** *list* $[neighbor, edge\\_cost]\\in G[current\\_node]$ **do**:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**if** $neighbor \\notin current\\_visited$ **then**:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$new\\_cost$ &larr; $current\\_cost + edge\\_cost$  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**if** $minDistanceK[neighbor] > new\\_cost$ **or** $current\\_stops + 1 < stops[neighbor]$ **then**:  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$minDistanceK[neighbor]$ &larr; $new\\_cost$  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$new\\_visited$ &larr; $current\\_visited \\cup \\{neighbor\\}$  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$priority\\_queue.\\mathbf{insert}((minDistanceK[neighbor], neighbor, current\\_stops + 1, new\\_visited))$  \n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**return** $minDistanceK[dst]$\n",
        "\n",
        "---\n",
        "**Function**: $findCheapestRouteDijkstra(n, flights, src, dest, k)$\n",
        "\n",
        "**Input**:\n",
        "- $n$: The *total number of vertices* in the graph.\n",
        "- $flights$: A list of edges in the form $[u, v, cost]$, where:\n",
        "  - $u$: The *source vertex*;\n",
        "  - $v$: The *destination vertex*;\n",
        "  - $cost$: *weight of the edge* from $u$ to $v$.\n",
        "- $src \\in V$: The *source vertex*;\n",
        "- $dst\\in V$: The *destination vertex*;\n",
        "- $k$: The *maximum number of edges allowed*.\n",
        "\n",
        "**Output**: The *minimum cost* to travel from $src$ to $dst$ crossing at the most $k$ edges, or $-1$ if no valid path exists.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;$G$ &larr; $\\mathbf{createAdjacencyList}(flights, n)$\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;$min\\_cost$ &larr; $\\mathbf{findMinCostDijkstra}(G, src, dst, k)$\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**if** $min\\_cost < \\infty$ **then**\\\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**return** $min\\_cost$\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;**return** $-1$\n",
        "\n",
        "#### Correctness Analysis\n",
        "The algorithm is correct because it processes states in increasing order of total cost, ensuring that when a state with the destination node is finally extracted from the priority queue, the corresponding cost is indeed minimal among all paths that use at most $k+1$ flights. It starts by pushing into the queue a single state with cost 0, node equal to the source, 0 stops, and a visited set containing only the source. By always extracting the state with the smallest cost first, it imitates Dijkstra’s logic, but it also keeps a set of visited nodes to forbid revisiting them in the same path and a stops counter that cannot exceed $k+1$. This means that each simple path of length up to $k+1$ flights is eventually considered in strictly increasing order of cost. If a state with node equal to the destination is popped, that state’s cost must be minimal among all valid paths; if such a state never appears, it implies that no valid path exists, and the algorithm returns -1.\n",
        "\n",
        "#### Time Complexity Analysis\n",
        "ChatGPT claimed that each node would appear in the priority queue at most $k+1$ times, leading to $O(n \\cdot k)$ total entries and a cost of $O(\\log(n \\cdot k))$ per extract-min operation, which would imply a time complexity of $O(m \\cdot \\log(n \\cdot k))$. However, this analysis overlooks the fact that the code stores the entire set of visited nodes in each state. This means that the same node can be inserted multiple times with different subsets of visited nodes, and these subsets can be numerous when $k$ is not very small. Indeed, each path can include up to $k+1$ distinct nodes, and a node can appear in the priority queue along with any of the subsets of already visited nodes. In the worst-case scenario, the number of such subsets can be on the order of $n^{k+1}$, as each of the $k+1$ nodes in the path can be chosen from $n$ possibilities, creating a combinatorial explosion. Once we acknowledge that the algorithm might enqueue on the order of $n^{k+1}$ states, the extract-min step on the priority queue, costing $O(\\log(n^{k+1}))$, turns into\n",
        "\\begin{align*}\n",
        "O\\bigl(n^{k+1} \\cdot \\log(n^{k+1})\\bigr),\n",
        "\\end{align*}\n",
        "and since $\\log(n^{k+1}) = (k+1)\\log(n)$, this simplifies to\n",
        "\\begin{align*}\n",
        "O\\bigl(n^{k+1} \\cdot k \\log n\\bigr).\n",
        "\\end{align*}\n",
        "Therefore, the actual worst-case time complexity of the code is exponential in $k$, rather than the more modest $O(m \\cdot \\log(n \\cdot k))$ described by ChatGPT. This exponential behavior stems from the large number of potential visited-subset configurations that can appear in the priority queue, invalidating ChatGPT’s claim that the total enqueues would be limited to just one state per node per stop-count.\n",
        "\n",
        "#### Comparison with Our Dynamic Programming Approach\n",
        "\n",
        "Our original algorithm employs a dynamic programming strategy, where we iteratively compute the minimum cost to reach each node with up to $k+1$ edges. The DP table is updated in each iteration based on the costs from the previous step, ensuring that we consider all possible paths within the stop constraint without revisiting nodes in the same path.\n",
        "\n",
        "ChatGPT's Dijkstra-like approach was initially described as having a time complexity of $O(m \\cdot \\log(n \\cdot k))$, where $m$ is the number of flights and $n$ is the number of nodes. This suggests that the algorithm scales efficiently with the number of flights and nodes, especially when $k$ is relatively small. However, this analysis does not account for the additional complexity introduced by tracking the set of visited nodes within each state. By maintaining these visited sets, the number of possible states that the algorithm must process can grow exponentially with respect to $k$. Specifically, in the worst case, the number of states can reach $O(n^{k+1})$, leading to a time complexity of $O(n^{k+1} \\cdot k \\cdot \\log n)$. This exponential growth makes ChatGPT's approach impractical for larger values of $k$, as the computation time becomes prohibitively large. In contrast, our dynamic programming approach operates with a time complexity of $O(k \\cdot n^2)$, which scales linearly with both the number of allowed stops and the number of flights. This linear relationship ensures that our algorithm remains efficient even as the size of the graph and the value of $k$ increase. By avoiding the need to track visited node sets and instead iteratively building up the minimum costs, our approach circumvents the combinatorial explosion inherent in ChatGPT's method.\n",
        "\n",
        "Both ChatGPT's approach and our dynamic programming method correctly identify the minimum cost path within the specified number of stops. ChatGPT's algorithm ensures correctness by processing nodes in order of increasing cost and adhering to the stop constraint. However, the inefficiency introduced by tracking visited sets compromises its practicality for larger problems. Our dynamic programming approach guarantees correctness by systematically updating the minimum costs for each node across all permissible numbers of stops, ensuring that the optimal path is found without unnecessary computational overhead.\n",
        "\n",
        "In conclusion, while ChatGPT's optimized Dijkstra-like algorithm maintains correctness in finding the cheapest route within the stop constraint, its exponential time complexity relative to $k$ renders it inefficient for larger values of $k$. Our dynamic programming approach, with its linear time complexity concerning both $k$ and the number of flights, offers a more scalable and practical solution. This makes our method better suited for handling extensive graphs and higher stop constraints, ensuring both efficiency and accuracy in diverse scenarios.\n",
        "\n",
        "#### Python Implementation\n",
        "We have implemented the `find_cheapest_route_Dijkstra` function in Python, which is located within the `functions.py` module. This function leverages the helper functions `create_adjacency_list` for constructing the graph's adjacency list and `min_cost_with_max_K_edges_Dijkstra` for computing the minimum cost route with the specified number of stops. To ensure the reliability and correctness of our implementation, we tested `find_cheapest_route_Dijkstra` using the same test cases previously described. The results consistently matched the expected outcomes, confirming that the algorithm performs as intended. For a more detailed explanation of the implementation and comprehensive comments, please refer to the `functions.py` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRjJ4FqclV20",
        "outputId": "d0600545-3e38-4dbb-97f8-17f8409fee4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flights: [[0, 1, 100], [1, 2, 100], [2, 0, 100], [1, 3, 600], [2, 3, 200]], source: 0, destination: 3, maximum number of stops: 1\n",
            "Cheapest route: 700\n",
            "\n",
            "Flights: [[0, 1, 100], [1, 2, 100], [0, 2, 500]], source: 0, destination: 2, maximum number of stops: 1\n",
            "Cheapest route: 200\n",
            "\n",
            "Flights: [[0, 1, 100], [1, 2, 100], [0, 2, 500]], source: 0, destination: 2, maximum number of stops: 0\n",
            "Cheapest route: 500\n",
            "\n",
            "Flights: [[0, 1, 100], [0, 2, 200], [1, 3, 300], [2, 3, 300]], source: 0, destination: 3, maximum number of stops: 2\n",
            "Cheapest route: 400\n",
            "\n",
            "Flights: [[0, 1, 100], [0, 2, 200], [1, 3, 300], [2, 3, 200]], source: 0, destination: 3, maximum number of stops: 2\n",
            "Cheapest route: 400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from functions import find_cheapest_route_Dijkstra\n",
        "\n",
        "n = [5, 3, 3, 4, 4]\n",
        "flights = [[[0, 1, 100], [1, 2, 100], [2, 0, 100], [1, 3, 600], [2, 3, 200]],\n",
        "           [[0, 1, 100], [1, 2, 100], [0, 2, 500]],\n",
        "           [[0, 1, 100], [1, 2, 100], [0, 2, 500]],\n",
        "           [[0, 1, 100], [0, 2, 200], [1, 3, 300], [2, 3, 300]],\n",
        "           [[0, 1, 100], [0, 2, 200], [1, 3, 300], [2, 3, 200]]]\n",
        "src = [0, 0, 0, 0, 0]\n",
        "dst = [3, 2, 2, 3, 3]\n",
        "k = [1, 1, 0, 2, 2]\n",
        "\n",
        "for i in range(len(n)):\n",
        "    result = find_cheapest_route_Dijkstra(n[i], flights[i], src[i], dst[i], k[i])\n",
        "    print(\"Flights: \" + str(flights[i]) +\n",
        "          \", source: \" + str(src[i]) +\n",
        "          \", destination: \" + str(dst[i]) +\n",
        "          \", maximum number of stops: \" + str(k[i]) +\n",
        "          \"\\nCheapest route: \" + str(result) + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}